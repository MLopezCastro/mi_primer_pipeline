

---


```markdown
# üß™ mi_primer_pipeline

Pipeline local en **Python** para **limpieza y validaci√≥n de datos de ventas**.  
Incluye modularizaci√≥n, ejecuci√≥n por **CLI**, y **logging** estructurado.  
Forma parte del **Desaf√≠o Semana 1** (Data Engineering).

---

## üöÄ Objetivo
Tomar un CSV crudo de ventas, aplicar transformaciones m√≠nimas y guardar un CSV limpio para an√°lisis.

**Transformaciones implementadas:**
- `clean_column_names()` ‚Äî normaliza nombres de columnas (min√∫sculas, sin tildes, sin espacios)
- `drop_nulls()` ‚Äî elimina filas con valores nulos
- `remove_empty_names()` ‚Äî elimina filas sin nombre de vendedor
- `filter_positive_values(col)` ‚Äî filtra filas con `cantidad` o `precio_unitario` ‚â§ 0
- `normalize_product_names()` ‚Äî normaliza nombres de producto (min√∫sculas, sin tildes)

---

## üìÇ Estructura
```

mi\_primer\_pipeline/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ input/                  # CSVs originales
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ventas\_raw\.csv
‚îÇ   ‚îî‚îÄ‚îÄ output/                 # CSVs procesados
‚îÇ       ‚îî‚îÄ‚îÄ ventas\_limpias.csv
‚îú‚îÄ‚îÄ pipeline/
‚îÇ   ‚îú‚îÄ‚îÄ load.py                 # load\_csv()
‚îÇ   ‚îú‚îÄ‚îÄ save.py                 # save\_csv()
‚îÇ   ‚îî‚îÄ‚îÄ transform.py            # funciones de transformaci√≥n
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îî‚îÄ‚îÄ logger.py               # get\_logger()
‚îú‚îÄ‚îÄ main.py                     # orquestaci√≥n + CLI
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md

````

---

## üß∞ Requisitos
- Python 3.10+
- venv activo
- Paquetes de `requirements.txt`

---

## ‚öôÔ∏è Instalaci√≥n r√°pida
```bash
# 1) crear/activar venv (Windows)
python -m venv .venv
.\.venv\Scripts\Activate

# Linux/Mac
python3 -m venv .venv
source .venv/bin/activate

# 2) instalar dependencias
pip install -r requirements.txt
````

---

## ‚ñ∂Ô∏è Uso (CLI)

Ejecutar con rutas expl√≠citas:

```bash
python main.py --input data/input/ventas_raw.csv --output data/output/ventas_limpias.csv
```

**Ejemplo de error controlado** (input inexistente):

```bash
python main.py --input data/input/no_existe.csv --output data/output/ventas_limpias.csv
# -> logger.error(...) y salida con c√≥digo 1
```

---

## üß™ Datos de ejemplo (para `data/input/ventas_raw.csv`)

```csv
Fecha,Vendedor,Producto,Cantidad,Precio Unitario
2025-07-15,Ana,Bicicleta,2,350
2025-07-15,,Bicicleta,1,350
2025-07-15,Marcos,Patineta,-1,120
2025-07-15,Luc√≠a,Monopat√≠n,1,NaN
2025-07-16,Pedro,Pat√≠n Electrico,3,500
```

**Salida esperada** (`data/output/ventas_limpias.csv`): solo filas v√°lidas, columnas normalizadas:

```
fecha,vendedor,producto,cantidad,precio_unitario
...
```

---

## üìù Logging esperado

* `logger.info()` al inicio/fin y antes/despu√©s de cada transformaci√≥n
* `logger.error()` si el archivo de entrada no existe

Salida t√≠pica:

```
YYYY-MM-DD HH:MM:SS | INFO | pipeline | === Inicio del pipeline ===
YYYY-MM-DD HH:MM:SS | INFO | pipeline.load | Cargado data/input/ventas_raw.csv | filas=5 cols=5
YYYY-MM-DD HH:MM:SS | INFO | pipeline | clean_column_names: filas 5 -> 5
YYYY-MM-DD HH:MM:SS | INFO | pipeline | drop_nulls: filas 5 -> 4
YYYY-MM-DD HH:MM:SS | INFO | pipeline | remove_empty_names: filas 4 -> 4
YYYY-MM-DD HH:MM:SS | INFO | pipeline | filter_positive_values(cantidad): filas 4 -> 3
YYYY-MM-DD HH:MM:SS | INFO | pipeline | filter_positive_values(precio_unitario): filas 3 -> 2
YYYY-MM-DD HH:MM:SS | INFO | pipeline | normalize_product_names: filas 2 -> 2
YYYY-MM-DD HH:MM:SS | INFO | pipeline.save | Guardado data/output/ventas_limpias.csv | filas=2 cols=5
YYYY-MM-DD HH:MM:SS | INFO | pipeline | === Fin del pipeline ===
```

---

## ‚úÖ Checklist (validaci√≥n del desaf√≠o)

* [x] Ejecutable desde consola (CLI con `argparse`)
* [x] Logging detallado (inicio/fin + antes/despu√©s de cada paso)
* [x] Output guardado en `data/output/`
* [x] Funciones bien nombradas y desacopladas (`load.py`, `transform.py`, `save.py`, `logger.py`)

---

## üß≠ Pr√≥ximos pasos

* Validaciones autom√°ticas (Semana 4)
* Ejecuci√≥n en AWS (Semana 2)
* Tests unitarios (Semana 8)
* Empaquetado y mejoras de producto

---

````

---

# requirements.txt (final)

```txt
pandas>=2.0
Unidecode>=1.3
````

---

# (Opcional) Atajos para correr por defecto

## Windows ‚Äî `run_pipeline.bat`

Gu√°rdalo en la ra√≠z del repo:

```bat
@echo off
REM Activa venv si hace falta (opcional)
IF NOT DEFINED VIRTUAL_ENV (
  call .\.venv\Scripts\activate
)

python main.py --input data\input\ventas_raw.csv --output data\output\ventas_limpias.csv
```

Ejecut√°s con doble click o:

```powershell
.\run_pipeline.bat
```

## Linux/Mac ‚Äî `run_pipeline.sh`

```bash
#!/usr/bin/env bash
source .venv/bin/activate 2>/dev/null || true
python main.py --input data/input/ventas_raw.csv --output data/output/ventas_limpias.csv
```

Y luego:

```bash
chmod +x run_pipeline.sh
./run_pipeline.sh
```

---

# √öltimo paso: commitear y subir

```bash
git add README.md requirements.txt run_pipeline.bat run_pipeline.sh
git commit -m "README + requirements + scripts de ejecuci√≥n"
git push
```


